{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Sentimiento a tweets en Español con el clasificador Support Vector Machine\n",
    "\n",
    "#### Tweets obtenidos de base de datos con tweets recolectados en español de usuarios con geolocalizacion en Guatemala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets class\n",
    "* 0 = negativo\n",
    "* 1 = positivo\n",
    "* 2 = neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieves data from db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve tweets from db\n",
    "conn = MySQLdb.connect(\"13.58.190.139\",\"root\",\"123\",\"tesis\" )\n",
    "data = pd.read_sql(\"select * from tweets where class is not null\", conn)\n",
    "data_copy = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split label from dataset\n",
    "y = data_copy[\"class\"]\n",
    "X = data_copy[\"text\"]\n",
    "\n",
    "#Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5958,), (1987,), (5958,), (1987,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spanish stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "# Spanish stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "analyzer = CountVectorizer(stop_words = spanish_stopwords).build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies stemmer function to text\n",
    "def customized_analyzer(doc):\n",
    "    stemmed_doc = []\n",
    "    for text in doc:\n",
    "        word_list = ''\n",
    "        for word in analyzer(text):\n",
    "            item = str(stemmer.stem(word))\n",
    "            word_list = word_list + \" \" + item\n",
    "        stemmed_doc.append(word_list)\n",
    "    return stemmed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                lowercase = True,\n",
    "                #ngram_range = (1,2),\n",
    "                stop_words = spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of Words from training set\n",
    "X_train_counts = vectorizer.fit_transform((X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train classifier with TF-IDF words weigth\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new_counts = vectorizer.transform((X_test))\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negativo       0.17      0.01      0.01       180\n",
      "   Positivo       0.46      0.33      0.39       501\n",
      "    Neutral       0.71      0.88      0.78      1306\n",
      "\n",
      "avg / total       0.60      0.66      0.61      1987\n",
      "\n",
      "[[   1   39  140]\n",
      " [   2  167  332]\n",
      " [   3  156 1147]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_counts, y_train)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_new_counts)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted, target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66180171112229491"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_new_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negativo       0.00      0.00      0.00       180\n",
      "   Positivo       0.50      0.21      0.30       501\n",
      "    Neutral       0.69      0.93      0.79      1306\n",
      "\n",
      "avg / total       0.58      0.67      0.60      1987\n",
      "\n",
      "[[   0   20  160]\n",
      " [   0  106  395]\n",
      " [   0   87 1219]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Try ussing TF IDF::\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_new_tfidf)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted, target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6668344237544036"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score del classificador\n",
    "model.score(X_new_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA:\n",
    "* Clasificador se comporta mejor usando TF-IDF\n",
    "* Clasificador necesita mas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'max_entropy.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
