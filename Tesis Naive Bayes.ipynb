{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Sentimiento a tweets en Español con el clasificador Naive Bayes\n",
    "\n",
    "#### Tweets obtenidos de base de datos con tweets recolectados en español de usuarios con geolocalizacion en Guatemala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets class\n",
    "* 0 = negativo\n",
    "* 1 = positivo\n",
    "* 2 = neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieves data from db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve tweets from db\n",
    "conn = MySQLdb.connect(\"13.58.190.139\",\"root\",\"123\",\"tesis\" )\n",
    "data = pd.read_sql(\"select * from tweets where class is not null limit 3650\", conn)\n",
    "data_copy = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split label from dataset\n",
    "y = data_copy[\"class\"]\n",
    "X = data_copy[\"text\"]\n",
    "\n",
    "#Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spanish stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "# Spanish stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "analyzer = CountVectorizer(stop_words = spanish_stopwords).build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies stemmer function to text\n",
    "def customized_analyzer(doc):\n",
    "    stemmed_doc = []\n",
    "    for text in doc:\n",
    "        word_list = ''\n",
    "        for word in analyzer(text):\n",
    "            item = str(stemmer.stem(word))\n",
    "            word_list = word_list + \" \" + item\n",
    "        stemmed_doc.append(word_list)\n",
    "    return stemmed_doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spanish stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                lowercase = True,\n",
    "                ngram_range = (1,3),\n",
    "                stop_words = spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of Words from training set\n",
    "X_train_counts = vectorizer.fit_transform((X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train classifier with TF-IDF words weigth\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier\n",
    "nv_classifier = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit classifier with test set\n",
    "X_new_counts = vectorizer.transform((X_test))\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = nv_classifier.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65498357064622126"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check accuracy\n",
    "np.mean(predicted == y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decode Labels from predicted output\n",
    "def decode_predicted(predicted_value):\n",
    "    predict_decode = []\n",
    "    for value in predicted_value:\n",
    "        if value == 0:\n",
    "            predict_decode.append(\"Negativo\")\n",
    "        else:\n",
    "            if value == 1:\n",
    "                predict_decode.append(\"Positivo\")\n",
    "            else:\n",
    "                predict_decode.append(\"Neutral\")\n",
    "    return predict_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove index from Series\n",
    "test_tweets = X_test.reset_index()\n",
    "predict_decode = decode_predicted(predicted)\n",
    "predicted_serie = pd.Series(predict_decode, index=None)\n",
    "\n",
    "#Convert Series to DataFrame\n",
    "df = pd.DataFrame(test_tweets, columns=['text'])\n",
    "df2 = predicted_serie.to_frame(name='predicted')\n",
    "df['predicted']=df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>me gustan las bodas rosa boda guatemala tu boda sonada URL</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>estar que bonito verbo</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>arabia saudita octava seleccion clasificada rusia2018 URL</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>que tiernos kcacolombia valentinazeneretrendy kcaargentina valentinazenere michaelronda URL</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>mejor me voy a mudar a r lyeh</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>el problema de la comida rapida es que es rapida menos cuando la necesitas la hora del almuerzo URL</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>fue de ayer y hasta ahorita la lei pinshi pamela</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>feliz martes</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>maria chula como marca y como nombre no deja de ser un nombre propio de origen hebreo un adjetivo que representa URL</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>cuando acabe la residencia me voy a dedicar a las artes</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     text  \\\n",
       "903                                                            me gustan las bodas rosa boda guatemala tu boda sonada URL   \n",
       "904                                                                                               estar que bonito verbo    \n",
       "905                                                             arabia saudita octava seleccion clasificada rusia2018 URL   \n",
       "906                           que tiernos kcacolombia valentinazeneretrendy kcaargentina valentinazenere michaelronda URL   \n",
       "907                                                                                         mejor me voy a mudar a r lyeh   \n",
       "908                   el problema de la comida rapida es que es rapida menos cuando la necesitas la hora del almuerzo URL   \n",
       "909                                                                     fue de ayer y hasta ahorita la lei pinshi pamela    \n",
       "910                                                                                                         feliz martes    \n",
       "911  maria chula como marca y como nombre no deja de ser un nombre propio de origen hebreo un adjetivo que representa URL   \n",
       "912                                                              cuando acabe la residencia me voy a dedicar a las artes    \n",
       "\n",
       "    predicted  \n",
       "903   Neutral  \n",
       "904   Neutral  \n",
       "905   Neutral  \n",
       "906   Neutral  \n",
       "907   Neutral  \n",
       "908   Neutral  \n",
       "909   Neutral  \n",
       "910  Positivo  \n",
       "911   Neutral  \n",
       "912   Neutral  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display results\n",
    "header_style = dict(selector=\"th\", props=[('text-align', 'left')])\n",
    "pd.set_option('display.max_colwidth',140)\n",
    "df.style.set_properties(**{'text-align':'left'}).set_table_styles([header_style])\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "### Classification code using Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=spanish_stopwords)),\n",
    "                      #('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68236582694414016"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(customized_analyzer(X_train), y_train)  \n",
    "predicted = text_clf.predict(customized_analyzer(X_test))\n",
    "np.mean(predicted == y_test) \n",
    "\n",
    "# Accuracy NOT using stemmer function: 0.4819\n",
    "# Accuracy setting n_grams range from 1-3: 0.4819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68236582694414016"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score del classificador\n",
    "text_clf.score(customized_analyzer(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66302368,  0.68978102,  0.70985401,  0.66849817,  0.66117216])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print cross validation score\n",
    "scores = cross_val_score(text_clf, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "### Probando Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57721796276013149"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classifier usando TDIDF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train_tfidf.toarray(), y_train).predict(X_new_tfidf.toarray())\n",
    "np.mean(y_pred == y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57721796276013149"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train_counts.toarray(), y_train).predict(X_new_counts.toarray())\n",
    "np.mean(y_pred == y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64403066812705367"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernulli Naive Bayes Classifier usando TDIDF\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "y_pred =(clf.predict(X_new_tfidf))\n",
    "np.mean(y_pred == y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64403066812705367"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernulli Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "y_pred =(clf.predict(X_new_counts))\n",
    "np.mean(y_pred == y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTAS: \n",
    "* Utilizar TF-IDF en texto reduce accuracy.\n",
    "* Utilizar steemr en texto reduce accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
