{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Sentimiento a tweets en Español con el clasificador Naive Bayes\n",
    "\n",
    "#### Tweets obtenidos de base de datos con tweets recolectados en español de usuarios con geolocalizacion en Guatemala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets class\n",
    "* 0 = negativo\n",
    "* 1 = positivo\n",
    "* 2 = neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve tweets from db\n",
    "conn = MySQLdb.connect(\"13.58.190.139\",\"root\",\"123\",\"tesis\" )\n",
    "data = pd.read_sql(\"select * from tweets where class is not null limit 2000\", conn)\n",
    "data_copy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split label from dataset\n",
    "y = data_copy[\"class\"]\n",
    "X = data_copy[\"text\"]\n",
    "\n",
    "#Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spanish stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "# Spanish stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "analyzer = CountVectorizer(stop_words = spanish_stopwords).build_analyzer()\n",
    "\n",
    "# Applies stemmer function to text\n",
    "def customized_analyzer(doc):\n",
    "    stemmed_doc = []\n",
    "    for text in doc:\n",
    "        word_list = ''\n",
    "        for word in analyzer(text):\n",
    "            item = str(stemmer.stem(word))\n",
    "            word_list = word_list + \" \" + item\n",
    "        stemmed_doc.append(word_list)\n",
    "    return stemmed_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spanish stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                lowercase = True,\n",
    "                ngram_range = (1,3),\n",
    "                stop_words = spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words from training set\n",
    "X_train_counts = vectorizer.fit_transform((X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train classifier with TF-IDF words weigth\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "nv_classifier = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit classifier with test set\n",
    "X_new_counts = vectorizer.transform((X_test))\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = nv_classifier.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48999999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check accuracy\n",
    "np.mean(predicted == y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode Labels from predicted output\n",
    "predict_decode = []\n",
    "for value in predicted:\n",
    "    if value == 0:\n",
    "        predict_decode.append(\"Negativo\")\n",
    "    else:\n",
    "        if value == 1:\n",
    "            predict_decode.append(\"Positivo\")\n",
    "        else:\n",
    "            predict_decode.append(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index from Series\n",
    "test_tweets = X_test.reset_index()\n",
    "predicted_serie = pd.Series(predict_decode, index=None)\n",
    "\n",
    "#Convert Series to DataFrame\n",
    "df = pd.DataFrame(test_tweets, columns=['text'])\n",
    "df2 = predicted_serie.to_frame(name='predicted')\n",
    "df['predicted']=df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>hay gente que quita hasta el hambre uish</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>AT USER AT USER AT USER eso decia yo solo que mejor compraran 5 o 10 radiopatrullas baratas pero funcionales</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>quiero conocer a rk ya de ya</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>despues de unos meses ya somos dos extranos</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>no llegues a detestarme si desaparezco</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>presidente en un discurso les dice a sus ministros si nos llevan a la carcel q nos lleven mal ejemp jimy a ministr URL</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>estos son los bebes de AT USER URL</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>senor librarme y guardarme de en medio de tanto celo</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>nada como alguien que te hace reir</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>si quieren pasen depositando su buenos dias con un corazon si no pues igual tengan buen dia culeros</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       text  \\\n",
       "490                                                                               hay gente que quita hasta el hambre uish    \n",
       "491           AT USER AT USER AT USER eso decia yo solo que mejor compraran 5 o 10 radiopatrullas baratas pero funcionales    \n",
       "492                                                                                           quiero conocer a rk ya de ya    \n",
       "493                                                                             despues de unos meses ya somos dos extranos   \n",
       "494                                                                                 no llegues a detestarme si desaparezco    \n",
       "495  presidente en un discurso les dice a sus ministros si nos llevan a la carcel q nos lleven mal ejemp jimy a ministr URL   \n",
       "496                                                                                      estos son los bebes de AT USER URL   \n",
       "497                                                                   senor librarme y guardarme de en medio de tanto celo    \n",
       "498                                                                                     nada como alguien que te hace reir    \n",
       "499                    si quieren pasen depositando su buenos dias con un corazon si no pues igual tengan buen dia culeros    \n",
       "\n",
       "    predicted  \n",
       "490  Negativo  \n",
       "491   Neutral  \n",
       "492   Neutral  \n",
       "493  Negativo  \n",
       "494   Neutral  \n",
       "495   Neutral  \n",
       "496   Neutral  \n",
       "497   Neutral  \n",
       "498   Neutral  \n",
       "499   Neutral  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display results\n",
    "header_style = dict(selector=\"th\", props=[('text-align', 'left')])\n",
    "pd.set_option('display.max_colwidth',140)\n",
    "df.style.set_properties(**{'text-align':'left'}).set_table_styles([header_style])\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification code using Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=spanish_stopwords)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(customized_analyzer(X_train), y_train)  \n",
    "predicted = text_clf.predict(customized_analyzer(X_test))\n",
    "np.mean(predicted == y_test) \n",
    "# Accuracy NOT using stemmer function: 0.4819\n",
    "# Accuracy setting n_grams range from 1-3: 0.4819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42599999999999999"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train_tfidf.toarray(), y_train).predict(X_new_tfidf.toarray())\n",
    "np.mean(y_pred == y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44800000000000001"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernulli Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "y_pred =(clf.predict(X_new_tfidf))\n",
    "np.mean(y_pred == y_test) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
