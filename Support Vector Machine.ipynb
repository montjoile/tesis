{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Sentimiento a tweets en Español con el clasificador Support Vector Machine\n",
    "\n",
    "#### Tweets obtenidos de base de datos con tweets recolectados en español de usuarios con geolocalizacion en Guatemala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets class\n",
    "* 0 = negativo\n",
    "* 1 = positivo\n",
    "* 2 = neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieves data from db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve tweets from db\n",
    "conn = MySQLdb.connect(\"13.58.190.139\",\"root\",\"123\",\"tesis\" )\n",
    "data = pd.read_sql(\"select * from tweets where class is not null\", conn)\n",
    "data_copy = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split label from dataset\n",
    "y = data_copy[\"class\"]\n",
    "X = data_copy[\"text\"]\n",
    "\n",
    "#Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5958,), (1987,), (5958,), (1987,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy indicators for column label\n",
    "y = pd.get_dummies(y, columns=[\"class\"], prefix=\"class\")\n",
    "#Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spanish stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "# Spanish stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "analyzer = CountVectorizer(stop_words = spanish_stopwords).build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies stemmer function to text\n",
    "def customized_analyzer(doc):\n",
    "    stemmed_doc = []\n",
    "    for text in doc:\n",
    "        word_list = ''\n",
    "        for word in analyzer(text):\n",
    "            item = str(stemmer.stem(word))\n",
    "            word_list = word_list + \" \" + item\n",
    "        stemmed_doc.append(word_list)\n",
    "    return stemmed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import spanish stopword\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                lowercase = True,\n",
    "                ngram_range = (1,3),\n",
    "                stop_words = spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of Words from training set\n",
    "X_train_counts = vectorizer.fit_transform((X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train classifier with TF-IDF words weigth\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new_counts = vectorizer.transform((X_test))\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65676899849018622"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, random_state=42)),\n",
    " ])\n",
    "text_clf.fit(X_train, y_train)  \n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negativo       0.17      0.01      0.01       180\n",
      "   Positivo       0.44      0.34      0.38       501\n",
      "    Neutral       0.71      0.87      0.78      1306\n",
      "\n",
      "avg / total       0.59      0.66      0.61      1987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(metrics.classification_report(y_test, predicted, target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))\n",
    "#metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy for different SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR SVC(kernel=rbf)\n",
      "Training time: 1.030719s; Prediction time: 0.224569s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negativo       0.00      0.00      0.00       180\n",
      "   Positivo       0.12      0.00      0.00       501\n",
      "    Neutral       0.66      1.00      0.79      1306\n",
      "\n",
      "avg / total       0.46      0.66      0.52      1987\n",
      "\n",
      "RESULTS FOR SVC(kernel=linear)\n",
      "Training time: 0.333240s; Prediction time: 0.059819s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negativo       0.00      0.00      0.00       180\n",
      "   Positivo       0.00      0.00      0.00       501\n",
      "    Neutral       0.66      1.00      0.79      1306\n",
      "\n",
      "avg / total       0.43      0.66      0.52      1987\n",
      "\n",
      "RESULTS FOR LinearSVC()\n",
      "Training time: 0.834805s; Prediction time: 0.000213s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negativo       0.00      0.00      0.00       180\n",
      "   Positivo       0.00      0.00      0.00       501\n",
      "    Neutral       0.66      1.00      0.79      1306\n",
      "\n",
      "avg / total       0.43      0.66      0.52      1987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf=True,stop_words = spanish_stopwords,\n",
    "                             use_idf=True)\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "# Perform classification with SVM, kernel=rbf\n",
    "classifier_rbf = svm.SVC()\n",
    "t0 = time.time()\n",
    "classifier_rbf.fit(X_train_counts, y_train)\n",
    "t1 = time.time()\n",
    "prediction_rbf = classifier_rbf.predict(X_new_counts)\n",
    "t2 = time.time()\n",
    "time_rbf_train = t1-t0\n",
    "time_rbf_predict = t2-t1\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(X_train_counts, y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(X_new_counts)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_liblinear = svm.LinearSVC()\n",
    "t0 = time.time()\n",
    "classifier_liblinear.fit(X_train_counts, y_train)\n",
    "t1 = time.time()\n",
    "prediction_liblinear = classifier_liblinear.predict(X_new_counts)\n",
    "t2 = time.time()\n",
    "time_liblinear_train = t1-t0\n",
    "time_liblinear_predict = t2-t1\n",
    "\n",
    "# Print results in a nice table\n",
    "print(\"RESULTS FOR SVC(kernel=rbf)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_rbf_train, time_rbf_predict))\n",
    "print(classification_report(y_test, prediction_rbf, target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))\n",
    "print(\"RESULTS FOR SVC(kernel=linear)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "print(classification_report(y_test, prediction_linear, target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))\n",
    "print(\"RESULTS FOR LinearSVC()\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_liblinear_train, time_liblinear_predict))\n",
    "print(classification_report(y_test, prediction_liblinear, target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR SVC(kernel=linear)\n",
      "Training time: 0.290675s; Prediction time: 0.059952s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negativo       0.00      0.00      0.00       180\n",
      "   Positivo       0.00      0.00      0.00       501\n",
      "    Neutral       0.66      1.00      0.79      1306\n",
      "\n",
      "avg / total       0.43      0.66      0.52      1987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Test Linear model using TF-IDF::\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(X_train_tfidf, y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(X_new_tfidf)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "print(\"RESULTS FOR SVC(kernel=linear)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "print(classification_report(y_test, prediction_linear, target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65727226975339703"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score del classificador\n",
    "classifier_linear.score(X_new_tfidf, y_test) #0.69112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR SVC(kernel=rbf) 0.655762455964\n",
      "RESULTS FOR SVC(kernel=linear) 0.657272269753\n",
      "RESULTS FOR LinearSVC() 0.657272269753\n"
     ]
    }
   ],
   "source": [
    "print(\"RESULTS FOR SVC(kernel=rbf)\",classifier_rbf.score(X_new_counts, y_test))\n",
    "print(\"RESULTS FOR SVC(kernel=linear)\",classifier_linear.score(X_new_counts, y_test))\n",
    "print(\"RESULTS FOR LinearSVC()\",classifier_liblinear.score(X_new_counts, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTAS:\n",
    "* El SVM con kernel lineal es el que da mejor accuracy \n",
    "* Usar TF-IDF incrementa el accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fd78d283150, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/sara/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/sara/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fd78d283150, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/sara/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/sara/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 15, 15, 50, 23, 549288, tzinfo=datetime.timezone.utc), 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'session': 'DDC86D33CA6341378925BC7D5C1BD619', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'DDC86D33CA6341378925BC7D5C1BD619']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 15, 15, 50, 23, 549288, tzinfo=datetime.timezone.utc), 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'session': 'DDC86D33CA6341378925BC7D5C1BD619', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'DDC86D33CA6341378925BC7D5C1BD619'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 15, 15, 50, 23, 549288, tzinfo=datetime.timezone.utc), 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'session': 'DDC86D33CA6341378925BC7D5C1BD619', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-64-2c3657452399>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fd74b9abba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fd74b9211e0, file \"<ipython-input-64-2c3657452399>\", line 36>\n        result = <ExecutionResult object at 7fd74b9abba8, executi..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fd74b9211e0, file \"<ipython-input-64-2c3657452399>\", line 36>, result=<ExecutionResult object at 7fd74b9abba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fd74b9211e0, file \"<ipython-input-64-2c3657452399>\", line 36>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import MySQLdb\\nimport pandas as pd\\nfrom sklearn....from sklearn.metrics import classification_report', '#Retrieve tweets from db\\nconn = MySQLdb.connect(...s is not null limit 3650\", conn)\\ndata_copy = data', '#Split label from dataset\\ny = data_copy[\"class\"]... y_test = train_test_split(X, y, random_state=42)', '# Import spanish stopword\\nspanish_stopwords = st...(stop_words = spanish_stopwords).build_analyzer()', '# Applies stemmer function to text\\ndef customize...mmed_doc.append(word_list)\\n    return stemmed_doc', '# Import spanish stopword\\nspanish_stopwords = st...,\\n                stop_words = spanish_stopwords)', '# Bag of Words from training set\\nX_train_counts = vectorizer.fit_transform((X_train))', '# Train classifier with TF-IDF words weigth\\ntfid...= tfidf_transformer.fit_transform(X_train_counts)', 'X_new_counts = vectorizer.transform((X_test))\\nX_...tfidf = tfidf_transformer.transform(X_new_counts)', \"text_clf = Pipeline([('vect', CountVectorizer())...clf.predict(X_test)\\nnp.mean(predicted == y_test) \", '# Print results\\nprint(metrics.classification_rep...\")))\\n#metrics.confusion_matrix(y_test, predicted)', '# Create feature vectors\\nvectorizer = TfidfVecto... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Test Linear model using TF-IDF::\\n\\n# Perform cl... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Score del classificador\\nclassifier_linear.score(X_new_tfidf, y_test)', \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", 'sklearn.model_selection.GridSearchCV\\n\\npipeline =...search.fit(customized_analyzer(X_train), y_train)', 'import sklearn.model_selection.GridSearchCV\\n\\npip...search.fit(customized_analyzer(X_train), y_train)', 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MySQLdb': <module 'MySQLdb' from '/home/sara/anaconda3/lib/python3.6/site-packages/MySQLdb/__init__.py'>, 'Out': {10: 0.6976998904709748, 14: 0.69112814895947428, 21: 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', 50: 0.6976998904709748, 54: 0.69112814895947428}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'SnowballStemmer': <class 'nltk.stem.snowball.SnowballStemmer'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import MySQLdb\\nimport pandas as pd\\nfrom sklearn....from sklearn.metrics import classification_report', '#Retrieve tweets from db\\nconn = MySQLdb.connect(...s is not null limit 3650\", conn)\\ndata_copy = data', '#Split label from dataset\\ny = data_copy[\"class\"]... y_test = train_test_split(X, y, random_state=42)', '# Import spanish stopword\\nspanish_stopwords = st...(stop_words = spanish_stopwords).build_analyzer()', '# Applies stemmer function to text\\ndef customize...mmed_doc.append(word_list)\\n    return stemmed_doc', '# Import spanish stopword\\nspanish_stopwords = st...,\\n                stop_words = spanish_stopwords)', '# Bag of Words from training set\\nX_train_counts = vectorizer.fit_transform((X_train))', '# Train classifier with TF-IDF words weigth\\ntfid...= tfidf_transformer.fit_transform(X_train_counts)', 'X_new_counts = vectorizer.transform((X_test))\\nX_...tfidf = tfidf_transformer.transform(X_new_counts)', \"text_clf = Pipeline([('vect', CountVectorizer())...clf.predict(X_test)\\nnp.mean(predicted == y_test) \", '# Print results\\nprint(metrics.classification_rep...\")))\\n#metrics.confusion_matrix(y_test, predicted)', '# Create feature vectors\\nvectorizer = TfidfVecto... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Test Linear model using TF-IDF::\\n\\n# Perform cl... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Score del classificador\\nclassifier_linear.score(X_new_tfidf, y_test)', \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", 'sklearn.model_selection.GridSearchCV\\n\\npipeline =...search.fit(customized_analyzer(X_train), y_train)', 'import sklearn.model_selection.GridSearchCV\\n\\npip...search.fit(customized_analyzer(X_train), y_train)', 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MySQLdb': <module 'MySQLdb' from '/home/sara/anaconda3/lib/python3.6/site-packages/MySQLdb/__init__.py'>, 'Out': {10: 0.6976998904709748, 14: 0.69112814895947428, 21: 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', 50: 0.6976998904709748, 54: 0.69112814895947428}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'SnowballStemmer': <class 'nltk.stem.snowball.SnowballStemmer'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/sara/Escritorio/tesis/<ipython-input-64-2c3657452399> in <module>()\n     31     'cls__max_iter': (500, 1000)\n     32 }\n     33 \n     34 \n     35 grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1 , scoring='roc_auc')\n---> 36 grid_search.fit(X_train, y_tparsed)\n     37 \n     38 \n     39 \n     40 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ..._score=True,\n       scoring='roc_auc', verbose=0), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...score=True,\n       scoring='roc_auc', verbose=0)>\n        X = 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object\n        y =       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns]\n        groups = None\n        self.param_grid = {'cls__C': (0.2, 0.5, 0.7), 'cls__loss': ('hinge', 'squared_hinge'), 'cls__max_iter': (500, 1000), 'vect__max_df': (0.5, 1.9), 'vect__max_features': (500, 1000), 'vect__min_df': (10, 20, 50), 'vect__ngram_range': ((1, 1), (1, 2))}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ..._score=True,\n       scoring='roc_auc', verbose=0), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Sep 15 09:50:23 2017\nPID: 21105                    Python 3.6.1: /home/sara/anaconda3/bin/python\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 913,  914,  915, ..., 2734, 2735, 2736]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), verbose=0, parameters={'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...2', random_state=None, tol=0.0001, verbose=0))])>\n        X_train = 2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object\n        y_train =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0.2, ...='l2', random_state=None, tol=0.0001, verbose=0)>\n        Xt = <1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0.2, class_weight=None, dual=True, f...y='l2', random_state=None, tol=0.0001, verbose=0), X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], sample_weight=None)\n    202         if self.C < 0:\n    203             raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n    204                              % self.C)\n    205 \n    206         X, y = check_X_y(X, y, accept_sparse='csr',\n--> 207                          dtype=np.float64, order=\"C\")\n    208         check_classification_targets(y)\n    209         self.classes_ = np.unique(y)\n    210 \n    211         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    521                     ensure_min_features, warn_on_dtype, estimator)\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n--> 526         y = column_or_1d(y, warn=True)\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n    527         _assert_all_finite(y)\n    528     if y_numeric and y.dtype.kind == 'O':\n    529         y = y.astype(np.float64)\n    530 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], warn=True)\n    557                           \" expected. Please change the shape of y to \"\n    558                           \"(n_samples, ), for example using ravel().\",\n    559                           _DataConversionWarning, stacklevel=2)\n    560         return np.ravel(y)\n    561 \n--> 562     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (1824, 3)\n    563 \n    564 \n    565 def check_random_state(seed):\n    566     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (1824, 3)\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 270, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py\", line 207, in fit\n    dtype=np.float64, order=\"C\")\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 526, in check_X_y\n    y = column_or_1d(y, warn=True)\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 562, in column_or_1d\n    raise ValueError(\"bad input shape {0}\".format(shape))\nValueError: bad input shape (1824, 3)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/sara/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Sep 15 09:50:23 2017\nPID: 21105                    Python 3.6.1: /home/sara/anaconda3/bin/python\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 913,  914,  915, ..., 2734, 2735, 2736]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), verbose=0, parameters={'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...2', random_state=None, tol=0.0001, verbose=0))])>\n        X_train = 2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object\n        y_train =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0.2, ...='l2', random_state=None, tol=0.0001, verbose=0)>\n        Xt = <1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0.2, class_weight=None, dual=True, f...y='l2', random_state=None, tol=0.0001, verbose=0), X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], sample_weight=None)\n    202         if self.C < 0:\n    203             raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n    204                              % self.C)\n    205 \n    206         X, y = check_X_y(X, y, accept_sparse='csr',\n--> 207                          dtype=np.float64, order=\"C\")\n    208         check_classification_targets(y)\n    209         self.classes_ = np.unique(y)\n    210 \n    211         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    521                     ensure_min_features, warn_on_dtype, estimator)\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n--> 526         y = column_or_1d(y, warn=True)\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n    527         _assert_all_finite(y)\n    528     if y_numeric and y.dtype.kind == 'O':\n    529         y = y.astype(np.float64)\n    530 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], warn=True)\n    557                           \" expected. Please change the shape of y to \"\n    558                           \"(n_samples, ), for example using ravel().\",\n    559                           _DataConversionWarning, stacklevel=2)\n    560         return np.ravel(y)\n    561 \n--> 562     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (1824, 3)\n    563 \n    564 \n    565 def check_random_state(seed):\n    566     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (1824, 3)\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Sep 15 09:50:23 2017\nPID: 21105                    Python 3.6.1: /home/sara/anaconda3/bin/python\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 913,  914,  915, ..., 2734, 2735, 2736]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), verbose=0, parameters={'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...2', random_state=None, tol=0.0001, verbose=0))])>\n        X_train = 2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object\n        y_train =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0.2, ...='l2', random_state=None, tol=0.0001, verbose=0)>\n        Xt = <1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0.2, class_weight=None, dual=True, f...y='l2', random_state=None, tol=0.0001, verbose=0), X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], sample_weight=None)\n    202         if self.C < 0:\n    203             raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n    204                              % self.C)\n    205 \n    206         X, y = check_X_y(X, y, accept_sparse='csr',\n--> 207                          dtype=np.float64, order=\"C\")\n    208         check_classification_targets(y)\n    209         self.classes_ = np.unique(y)\n    210 \n    211         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    521                     ensure_min_features, warn_on_dtype, estimator)\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n--> 526         y = column_or_1d(y, warn=True)\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n    527         _assert_all_finite(y)\n    528     if y_numeric and y.dtype.kind == 'O':\n    529         y = y.astype(np.float64)\n    530 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], warn=True)\n    557                           \" expected. Please change the shape of y to \"\n    558                           \"(n_samples, ), for example using ravel().\",\n    559                           _DataConversionWarning, stacklevel=2)\n    560         return np.ravel(y)\n    561 \n--> 562     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (1824, 3)\n    563 \n    564 \n    565 def check_random_state(seed):\n    566     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (1824, 3)\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-2c3657452399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fd78d283150, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/sara/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/sara/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fd78d283150, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/sara/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/sara/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 15, 15, 50, 23, 549288, tzinfo=datetime.timezone.utc), 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'session': 'DDC86D33CA6341378925BC7D5C1BD619', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'DDC86D33CA6341378925BC7D5C1BD619']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 15, 15, 50, 23, 549288, tzinfo=datetime.timezone.utc), 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'session': 'DDC86D33CA6341378925BC7D5C1BD619', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'DDC86D33CA6341378925BC7D5C1BD619'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 15, 15, 50, 23, 549288, tzinfo=datetime.timezone.utc), 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'session': 'DDC86D33CA6341378925BC7D5C1BD619', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ADB701D99DD643CBA4D8F1EF44F0C121', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#Create dummy indicators for column label\\n#y = p...ng='roc_auc')\\ngrid_search.fit(X_train, y_tparsed)\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-64-2c3657452399>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fd74b9abba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fd74b9211e0, file \"<ipython-input-64-2c3657452399>\", line 36>\n        result = <ExecutionResult object at 7fd74b9abba8, executi..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fd74b9211e0, file \"<ipython-input-64-2c3657452399>\", line 36>, result=<ExecutionResult object at 7fd74b9abba8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fd74b9211e0, file \"<ipython-input-64-2c3657452399>\", line 36>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import MySQLdb\\nimport pandas as pd\\nfrom sklearn....from sklearn.metrics import classification_report', '#Retrieve tweets from db\\nconn = MySQLdb.connect(...s is not null limit 3650\", conn)\\ndata_copy = data', '#Split label from dataset\\ny = data_copy[\"class\"]... y_test = train_test_split(X, y, random_state=42)', '# Import spanish stopword\\nspanish_stopwords = st...(stop_words = spanish_stopwords).build_analyzer()', '# Applies stemmer function to text\\ndef customize...mmed_doc.append(word_list)\\n    return stemmed_doc', '# Import spanish stopword\\nspanish_stopwords = st...,\\n                stop_words = spanish_stopwords)', '# Bag of Words from training set\\nX_train_counts = vectorizer.fit_transform((X_train))', '# Train classifier with TF-IDF words weigth\\ntfid...= tfidf_transformer.fit_transform(X_train_counts)', 'X_new_counts = vectorizer.transform((X_test))\\nX_...tfidf = tfidf_transformer.transform(X_new_counts)', \"text_clf = Pipeline([('vect', CountVectorizer())...clf.predict(X_test)\\nnp.mean(predicted == y_test) \", '# Print results\\nprint(metrics.classification_rep...\")))\\n#metrics.confusion_matrix(y_test, predicted)', '# Create feature vectors\\nvectorizer = TfidfVecto... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Test Linear model using TF-IDF::\\n\\n# Perform cl... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Score del classificador\\nclassifier_linear.score(X_new_tfidf, y_test)', \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", 'sklearn.model_selection.GridSearchCV\\n\\npipeline =...search.fit(customized_analyzer(X_train), y_train)', 'import sklearn.model_selection.GridSearchCV\\n\\npip...search.fit(customized_analyzer(X_train), y_train)', 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MySQLdb': <module 'MySQLdb' from '/home/sara/anaconda3/lib/python3.6/site-packages/MySQLdb/__init__.py'>, 'Out': {10: 0.6976998904709748, 14: 0.69112814895947428, 21: 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', 50: 0.6976998904709748, 54: 0.69112814895947428}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'SnowballStemmer': <class 'nltk.stem.snowball.SnowballStemmer'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import MySQLdb\\nimport pandas as pd\\nfrom sklearn....from sklearn.metrics import classification_report', '#Retrieve tweets from db\\nconn = MySQLdb.connect(...s is not null limit 3650\", conn)\\ndata_copy = data', '#Split label from dataset\\ny = data_copy[\"class\"]... y_test = train_test_split(X, y, random_state=42)', '# Import spanish stopword\\nspanish_stopwords = st...(stop_words = spanish_stopwords).build_analyzer()', '# Applies stemmer function to text\\ndef customize...mmed_doc.append(word_list)\\n    return stemmed_doc', '# Import spanish stopword\\nspanish_stopwords = st...,\\n                stop_words = spanish_stopwords)', '# Bag of Words from training set\\nX_train_counts = vectorizer.fit_transform((X_train))', '# Train classifier with TF-IDF words weigth\\ntfid...= tfidf_transformer.fit_transform(X_train_counts)', 'X_new_counts = vectorizer.transform((X_test))\\nX_...tfidf = tfidf_transformer.transform(X_new_counts)', \"text_clf = Pipeline([('vect', CountVectorizer())...clf.predict(X_test)\\nnp.mean(predicted == y_test) \", '# Print results\\nprint(metrics.classification_rep...\")))\\n#metrics.confusion_matrix(y_test, predicted)', '# Create feature vectors\\nvectorizer = TfidfVecto... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Test Linear model using TF-IDF::\\n\\n# Perform cl... target_names=(\"Negativo\",\"Positivo\",\"Neutral\")))', '# Score del classificador\\nclassifier_linear.score(X_new_tfidf, y_test)', \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", \"pipeline = Pipeline([\\n    ('vect', vectorizer),\\n...search.fit(customized_analyzer(X_train), y_train)\", 'sklearn.model_selection.GridSearchCV\\n\\npipeline =...search.fit(customized_analyzer(X_train), y_train)', 'import sklearn.model_selection.GridSearchCV\\n\\npip...search.fit(customized_analyzer(X_train), y_train)', 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'MySQLdb': <module 'MySQLdb' from '/home/sara/anaconda3/lib/python3.6/site-packages/MySQLdb/__init__.py'>, 'Out': {10: 0.6976998904709748, 14: 0.69112814895947428, 21: 'from sklearn.model_selection import GridSearchCV...search.fit(customized_analyzer(X_train), y_train)', 50: 0.6976998904709748, 54: 0.69112814895947428}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'SnowballStemmer': <class 'nltk.stem.snowball.SnowballStemmer'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/sara/Escritorio/tesis/<ipython-input-64-2c3657452399> in <module>()\n     31     'cls__max_iter': (500, 1000)\n     32 }\n     33 \n     34 \n     35 grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1 , scoring='roc_auc')\n---> 36 grid_search.fit(X_train, y_tparsed)\n     37 \n     38 \n     39 \n     40 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ..._score=True,\n       scoring='roc_auc', verbose=0), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...score=True,\n       scoring='roc_auc', verbose=0)>\n        X = 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object\n        y =       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns]\n        groups = None\n        self.param_grid = {'cls__C': (0.2, 0.5, 0.7), 'cls__loss': ('hinge', 'squared_hinge'), 'cls__max_iter': (500, 1000), 'vect__max_df': (0.5, 1.9), 'vect__max_features': (500, 1000), 'vect__min_df': (10, 20, 50), 'vect__ngram_range': ((1, 1), (1, 2))}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ..._score=True,\n       scoring='roc_auc', verbose=0), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Sep 15 09:50:23 2017\nPID: 21105                    Python 3.6.1: /home/sara/anaconda3/bin/python\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), 318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object,       class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], make_scorer(roc_auc_score, needs_threshold=True), array([ 913,  914,  915, ..., 2734, 2735, 2736]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), 0, {'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=318                      AT USER si pero no en e...co lunes \nName: text, Length: 2737, dtype: object, y=      class_0  class_1  class_2\n318         0   ...     0        1        0\n\n[2737 rows x 3 columns], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 913,  914,  915, ..., 2734, 2735, 2736]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 905, 906, 907, 908, 909,\n       910, 911, 912]), verbose=0, parameters={'cls__C': 0.2, 'cls__loss': 'hinge', 'cls__max_iter': 500, 'vect__max_df': 0.5, 'vect__max_features': 500, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...2', random_state=None, tol=0.0001, verbose=0))])>\n        X_train = 2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object\n        y_train =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...l2', random_state=None, tol=0.0001, verbose=0))]), X=2202    hoy los hermanos de la iglesia se antici...co lunes \nName: text, Length: 1824, dtype: object, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0.2, ...='l2', random_state=None, tol=0.0001, verbose=0)>\n        Xt = <1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0.2, class_weight=None, dual=True, f...y='l2', random_state=None, tol=0.0001, verbose=0), X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], sample_weight=None)\n    202         if self.C < 0:\n    203             raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n    204                              % self.C)\n    205 \n    206         X, y = check_X_y(X, y, accept_sparse='csr',\n--> 207                          dtype=np.float64, order=\"C\")\n    208         check_classification_targets(y)\n    209         self.classes_ = np.unique(y)\n    210 \n    211         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=<1824x160 sparse matrix of type '<class 'numpy.f... stored elements in Compressed Sparse Row format>, y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    521                     ensure_min_features, warn_on_dtype, estimator)\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n--> 526         y = column_or_1d(y, warn=True)\n        y =       class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns]\n    527         _assert_all_finite(y)\n    528     if y_numeric and y.dtype.kind == 'O':\n    529         y = y.astype(np.float64)\n    530 \n\n...........................................................................\n/home/sara/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in column_or_1d(y=      class_0  class_1  class_2\n2202        0   ...     0        1        0\n\n[1824 rows x 3 columns], warn=True)\n    557                           \" expected. Please change the shape of y to \"\n    558                           \"(n_samples, ), for example using ravel().\",\n    559                           _DataConversionWarning, stacklevel=2)\n    560         return np.ravel(y)\n    561 \n--> 562     raise ValueError(\"bad input shape {0}\".format(shape))\n        shape = (1824, 3)\n    563 \n    564 \n    565 def check_random_state(seed):\n    566     \"\"\"Turn seed into a np.random.RandomState instance\n\nValueError: bad input shape (1824, 3)\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#Create dummy indicators for column label\n",
    "#y = pd.get_dummies(y, columns=[\"class\"], prefix=\"class\")\n",
    "#Split dataset into training and test set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "'''y = label_binarize(y, classes=[0, 1, 2, 3])\n",
    "clf_SVM = OneVsRestClassifier(LinearSVC())\n",
    "params = {\n",
    "      'estimator__C': [0.5, 1.0, 1.5],\n",
    "      'estimator__tol': [1e-3, 1e-4, 1e-5],\n",
    "      }\n",
    "gs = GridSearchCV(clf_SVM, params, cv=5, scoring='roc_auc')\n",
    "gs.fit(corpus1, y)'''\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', svm.LinearSVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 1.9),\n",
    "    'vect__min_df': (10, 20,50),\n",
    "    'vect__max_features': (500, 1000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'cls__C': (0.2, 0.5, 0.7),\n",
    "    'cls__loss': ('hinge', 'squared_hinge'),\n",
    "    'cls__max_iter': (500, 1000)\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1 , scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_tparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tparsed = pd.get_dummies(y_train, columns=[\"class\"], prefix=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class_0  class_1  class_2\n",
       "318         0        0        1\n",
       "816         0        0        1\n",
       "2636        0        0        1\n",
       "59          0        1        0\n",
       "3257        0        0        1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tparsed.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
